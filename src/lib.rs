use crate::anvil_api::auth_service_server::AuthServiceServer;
use crate::anvil_api::bucket_service_server::BucketServiceServer;
use crate::anvil_api::internal_anvil_service_server::InternalAnvilServiceServer;
use crate::anvil_api::object_service_server::ObjectServiceServer;
use crate::auth::JwtManager;
use anyhow::Result;
use axum::handler::Handler;
use cluster::ClusterState;
use deadpool_postgres::{ManagerConfig, Pool, RecyclingMethod};
use std::collections::HashMap;
use std::str::FromStr;
use std::sync::Arc;
use tokio::sync::RwLock;
use tokio_postgres::NoTls;
use tower::MakeService;

// The modules we've created
pub mod auth;
pub mod cluster;
pub mod discovery;
pub mod middleware;
pub mod persistence;
pub mod placement;
pub mod s3_auth;
pub mod s3_gateway;
pub mod services;
pub mod sharding;
pub mod storage;
pub mod worker;

// The gRPC code generated by tonic-build
pub mod anvil_api {
    tonic::include_proto!("anvil");
}

pub mod migrations {
    use refinery_macros::embed_migrations;
    embed_migrations!("./migrations_global");
}

pub mod regional_migrations {
    use refinery_macros::embed_migrations;
    embed_migrations!("./migrations_regional");
}

// Our application state, which will hold the persistence layer, storage engine, etc.
#[derive(Clone)]
pub struct AppState {
    pub db: persistence::Persistence,
    pub storage: storage::Storage,
    pub cluster: ClusterState,
    pub sharder: sharding::ShardManager,
    pub placer: placement::PlacementManager,
    pub jwt_manager: Arc<JwtManager>,
    pub region: String,
}
impl AppState {
    pub async fn new(
        global_pool: Pool,
        regional_pool: Pool,
        region: String,
        jwt_secret: String,
    ) -> Result<Self> {
        let jwt_manager = Arc::new(JwtManager::new(jwt_secret));
        let storage = storage::Storage::new().await?;
        let cluster_state = Arc::new(RwLock::new(HashMap::new()));
        Ok(Self {
            db: persistence::Persistence::new(global_pool, regional_pool),
            storage,
            cluster: cluster_state.clone(),
            sharder: sharding::ShardManager::new(),
            placer: placement::PlacementManager::default(),
            jwt_manager,
            region: region.clone(),
        })
    }
}
pub async fn run(
    listener: tokio::net::TcpListener,
    region: String,
    global_db_url: String,
    regional_db_url: String,
    jwt_secret: String,
) -> Result<()> {
    // --- Database ---
    // Create connection pools
    let regional_pool = create_pool(&regional_db_url)?;
    let global_pool = create_pool(&global_db_url)?;

    // Run migrations on both databases
    run_migrations(
        &global_db_url,
        migrations::migrations::runner(),
        "refinery_schema_history_global",
    )
    .await?;
    run_migrations(
        &regional_db_url,
        regional_migrations::migrations::runner(),
        "refinery_schema_history_regional",
    )
    .await?;

    // Create a default tenant for testing if it doesn't exist
    let client = global_pool.get().await?;
    client
        .execute(
            "INSERT INTO tenants (id, name, api_key) VALUES (1, 'default', 'default-key') ON CONFLICT (id) DO NOTHING",
            &[],
        )
        .await?;
    client
        .execute(
            "INSERT INTO regions (name) VALUES ($1) ON CONFLICT (name) DO NOTHING",
            &[&region],
        )
        .await?;

    // --- State ---
    let state = AppState::new(global_pool, regional_pool, region, jwt_secret).await?;

    let worker_state = state.clone();
    tokio::spawn(async move {
        if let Err(e) = worker::run(worker_state.db).await {
            eprintln!("Worker process failed: {}", e);
        }
    });

    // --- Services ---
    let state_clone = state.clone();
    let auth_interceptor = move |req| middleware::auth_interceptor(req, &state_clone);

    // Create the gRPC router, applying the interceptor to each protected service.
    let grpc_router = tonic::service::Routes::new(AuthServiceServer::new(state.clone()))
        .add_service(ObjectServiceServer::with_interceptor(
            state.clone(),
            auth_interceptor.clone(),
        ))
        .add_service(BucketServiceServer::with_interceptor(
            state.clone(),
            auth_interceptor.clone(),
        ))
        .add_service(InternalAnvilServiceServer::with_interceptor(
            state.clone(),
            auth_interceptor,
        ));

    // Create the Axum router for S3 and merge the gRPC router into it.
    let app = s3_gateway::app(state.clone()).merge(grpc_router.into_axum_router());

    let addr = listener.local_addr()?;
    println!("Anvil server (gRPC & S3) listening on {}", addr);

    // Spawn the gossip service to run in the background.
    let gossip_task = tokio::spawn(cluster::run_gossip(
        cluster::create_swarm().await?,
        state.cluster,
        format!("http://{}", addr),
    ));
    let server_task =
        tokio::spawn(async move { axum::serve(listener, app.into_make_service()).await });

    // Run both tasks concurrently.
    let (server_result, gossip_result) = tokio::join!(server_task, gossip_task);
    server_result??;
    gossip_result??;

    Ok(())
}

pub fn create_pool(db_url: &str) -> Result<Pool> {
    let pg_config = tokio_postgres::Config::from_str(db_url)?;
    let mgr_config = ManagerConfig {
        recycling_method: RecyclingMethod::Fast,
    };
    let mgr = deadpool_postgres::Manager::from_config(pg_config, NoTls, mgr_config);
    Pool::builder(mgr).build().map_err(Into::into)
}

pub async fn run_migrations(
    db_url: &str,
    mut runner: refinery::Runner,
    table_name: &str,
) -> Result<()> {
    let (mut client, connection) = tokio_postgres::connect(db_url, NoTls).await?;
    tokio::spawn(async move {
        if let Err(e) = connection.await {
            eprintln!("connection error: {}", e);
        }
    });
    runner
        .set_migration_table_name(table_name)
        .run_async(&mut client)
        .await?;
    Ok(())
}

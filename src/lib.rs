use crate::anvil_api::auth_service_server::AuthServiceServer;
use crate::anvil_api::bucket_service_server::BucketServiceServer;
use crate::anvil_api::internal_anvil_service_server::InternalAnvilServiceServer;
use crate::anvil_api::object_service_server::ObjectServiceServer;
use crate::auth::JwtManager;
use anyhow::Result;
use cluster::ClusterState;
use deadpool_postgres::{ManagerConfig, Pool, RecyclingMethod};
use std::collections::HashMap;
use std::env;
use std::net::SocketAddr;
use std::str::FromStr;
use std::sync::Arc;
use tokio::sync::RwLock;
use tokio_postgres::NoTls;
use tonic::transport::Server;

// The modules we've created
pub mod auth;
pub mod cluster;
pub mod discovery;
pub mod persistence;
pub mod placement;
pub mod services;
pub mod sharding;
pub mod storage;

pub mod middleware;

// The gRPC code generated by tonic-build
pub mod anvil_api {
    tonic::include_proto!("anvil");
}

pub mod migrations {
    use refinery_macros::embed_migrations;
    embed_migrations!("./migrations_global");
}

pub mod regional_migrations {
    use refinery_macros::embed_migrations;
    embed_migrations!("./migrations_regional");
}

// Our application state, which will hold the persistence layer, storage engine, etc.
#[derive(Clone)]
pub struct AppState {
    pub db: persistence::Persistence,
    pub storage: storage::Storage,
    pub cluster: ClusterState,
    pub sharder: sharding::ShardManager,
    pub placer: placement::PlacementManager,
    pub jwt_manager: Arc<JwtManager>,
    pub region: String,
}

pub async fn run(grpc_addr: SocketAddr) -> Result<()> {
    // --- Database ---
    let region = env::var("REGION").expect("REGION must be set");
    let regional_db_url = env::var(format!("DATABASE_URL_REGION_{}", region.to_uppercase()))
        .expect("Regional DATABASE_URL must be set");
    let global_db_url = env::var("GLOBAL_DATABASE_URL").expect("Global DATABASE_URL must be set");

    // Create connection pools
    let regional_pool = create_pool(&regional_db_url)?;
    let global_pool = create_pool(&global_db_url)?;

    // Run migrations on both databases
    run_migrations(
        &global_db_url,
        migrations::migrations::runner(),
        "refinery_schema_history_global",
    )
    .await?;
    run_migrations(
        &regional_db_url,
        regional_migrations::migrations::runner(),
        "refinery_schema_history_regional",
    )
    .await?;

    // Create a default tenant for testing if it doesn't exist
    let client = global_pool.get().await?;
    client
        .execute(
            "INSERT INTO tenants (id, name, api_key) VALUES (1, 'default', 'default-key') ON CONFLICT (id) DO NOTHING",
            &[],
        )
        .await?;
    client
        .execute(
            "INSERT INTO regions (name) VALUES ($1) ON CONFLICT (name) DO NOTHING",
            &[&region],
        )
        .await?;
    let jwt_secret = env::var("JWT_SECRET").expect("JWT_SECRET must be set");
    let jwt_manager = Arc::new(JwtManager::new(jwt_secret));

    // --- State ---
    let storage = storage::Storage::new().await?;
    let cluster_state = Arc::new(RwLock::new(HashMap::new()));
    let state = AppState {
        db: persistence::Persistence::new(global_pool, regional_pool),
        storage,
        cluster: cluster_state.clone(),
        sharder: sharding::ShardManager::new(),
        placer: placement::PlacementManager::default(),
        jwt_manager,
        region: region.clone(),
    };

    // --- Services ---
    let state_clone = state.clone();
    let auth_interceptor = move |req| middleware::auth_interceptor(req, &state_clone);

    let grpc_server = Server::builder()
        .add_service(AuthServiceServer::new(state.clone()))
        .add_service(ObjectServiceServer::with_interceptor(
            state.clone(),
            auth_interceptor.clone(),
        ))
        .add_service(BucketServiceServer::with_interceptor(
            state.clone(),
            auth_interceptor.clone(),
        ))
        .add_service(InternalAnvilServiceServer::with_interceptor(
            state,
            auth_interceptor,
        ))
        .serve(grpc_addr);

    let swarm = cluster::create_swarm().await?;
    let gossip_service = cluster::run_gossip(swarm, cluster_state, format!("http://{}", grpc_addr));

    println!("Anvil gRPC server listening on {}", grpc_addr);

    // --- Run ---
    tokio::try_join!(
        async { grpc_server.await.map_err(anyhow::Error::from) },
        async { gossip_service.await.map_err(anyhow::Error::from) },
    )?;

    Ok(())
}

pub fn create_pool(db_url: &str) -> Result<Pool> {
    let pg_config = tokio_postgres::Config::from_str(db_url)?;
    let mgr_config = ManagerConfig {
        recycling_method: RecyclingMethod::Fast,
    };
    let mgr = deadpool_postgres::Manager::from_config(pg_config, NoTls, mgr_config);
    Pool::builder(mgr).build().map_err(Into::into)
}

pub async fn run_migrations(
    db_url: &str,
    mut runner: refinery::Runner,
    table_name: &str,
) -> Result<()> {
    let (mut client, connection) = tokio_postgres::connect(db_url, NoTls).await?;
    tokio::spawn(async move {
        if let Err(e) = connection.await {
            eprintln!("connection error: {}", e);
        }
    });
    runner
        .set_migration_table_name(table_name)
        .run_async(&mut client)
        .await?;
    Ok(())
}
